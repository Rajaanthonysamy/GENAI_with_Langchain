{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have feelings, but I'm here and ready to assist you! How can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 14, 'total_tokens': 46, 'completion_time': 0.058181818, 'prompt_time': 0.000133159, 'queue_time': 0.014845550999999998, 'total_time': 0.058314977}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2cdab616-40f8-4ede-89c9-57203ff94d30-0', usage_metadata={'input_tokens': 14, 'output_tokens': 32, 'total_tokens': 46})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage , SystemMessage\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following from english to freanch\"),\n",
    "    HumanMessage(content=\"Hello how are you?\")\n",
    "]\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hello how are you?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You are right! I apologize for that. I am still learning social cues.  \\n\\nHow are you doing today? üòä  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 62, 'total_tokens': 92, 'completion_time': 0.054545455, 'prompt_time': 0.001902466, 'queue_time': 0.011755241999999999, 'total_time': 0.056447921}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c76a5534-44d3-46ad-ae57-0c5857da3c3c-0', usage_metadata={'input_tokens': 62, 'output_tokens': 30, 'total_tokens': 92})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([HumanMessage(content=\"Hello how are you?\"),\n",
    "              AIMessage(content=\"As an AI, I don't have feelings, but I'm here and ready to assist you! How can I help you today?\\n\"),\n",
    "              HumanMessage(content=\"dont you ask how i was doing?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_msg_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"Hi I am Raja Anthonysamy and profession is data scientist\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Raja Anthonysamy! \\n\\nThat's a fascinating profession. What kind of data science work do you do?  \\n\\nI'm always eager to learn more about different fields and how people use technology to solve problems. üòÑ  \\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Raja Anthonysamy. üòä  I remember!  \\n\\n\\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat_2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to use it!\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have.\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 14, 'total_tokens': 63, 'completion_time': 0.089090909, 'prompt_time': 0.000209279, 'queue_time': 0.019981411, 'total_time': 0.089300188}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2a54229b-3ea0-4640-ad95-b9732dd9dc77-0', usage_metadata={'input_tokens': 14, 'output_tokens': 49, 'total_tokens': 63}), HumanMessage(content='Hello how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thank you! \\n\\nHow are you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 76, 'total_tokens': 97, 'completion_time': 0.038181818, 'prompt_time': 0.003537059, 'queue_time': 0.018536947, 'total_time': 0.041718877}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ca6e1f36-9b93-4140-a08b-ba89f6776f13-0', usage_metadata={'input_tokens': 76, 'output_tokens': 21, 'total_tokens': 97}), HumanMessage(content='Hi I am Raja Anthonysamy and profession is data scientist', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Raja Anthonysamy! \\n\\nThat's a fascinating profession. What kind of data science work do you do?  \\n\\nI'm always eager to learn more about different fields and how people use technology to solve problems. üòÑ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 118, 'total_tokens': 179, 'completion_time': 0.110909091, 'prompt_time': 0.008512123, 'queue_time': 0.0066734870000000005, 'total_time': 0.119421214}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-70aaac92-f402-42e0-a03f-1c8a66186558-0', usage_metadata={'input_tokens': 118, 'output_tokens': 61, 'total_tokens': 179}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Raja Anthonysamy. üòä  I remember!  \\n\\n\\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 192, 'total_tokens': 221, 'completion_time': 0.052727273, 'prompt_time': 0.007144538, 'queue_time': 0.007442242000000001, 'total_time': 0.059871811}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-63df76e2-5bb1-4bb5-89fc-0a4eef06ae64-0', usage_metadata={'input_tokens': 192, 'output_tokens': 29, 'total_tokens': 221})]),\n",
       " 'chat_2': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 15, 'total_tokens': 53, 'completion_time': 0.069090909, 'prompt_time': 9.9079e-05, 'queue_time': 0.015150921, 'total_time': 0.069189988}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c77e912b-d346-46f8-b218-d63b931bd163-0', usage_metadata={'input_tokens': 15, 'output_tokens': 38, 'total_tokens': 53})])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"Do you know Raja Anthonysamy\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have access to real-time information or personal details about individuals like Raja Anthonysamy. To find information about someone, you could try searching online using a search engine. \\n\\nIs there something specific you'd like to know about Raja Anthonysamy? Perhaps I could help you find relevant information online.\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have.\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 14, 'total_tokens': 63, 'completion_time': 0.089090909, 'prompt_time': 0.000209279, 'queue_time': 0.019981411, 'total_time': 0.089300188}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2a54229b-3ea0-4640-ad95-b9732dd9dc77-0', usage_metadata={'input_tokens': 14, 'output_tokens': 49, 'total_tokens': 63}), HumanMessage(content='Hello how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thank you! \\n\\nHow are you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 76, 'total_tokens': 97, 'completion_time': 0.038181818, 'prompt_time': 0.003537059, 'queue_time': 0.018536947, 'total_time': 0.041718877}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ca6e1f36-9b93-4140-a08b-ba89f6776f13-0', usage_metadata={'input_tokens': 76, 'output_tokens': 21, 'total_tokens': 97}), HumanMessage(content='Hi I am Raja Anthonysamy and profession is data scientist', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Raja Anthonysamy! \\n\\nThat's a fascinating profession. What kind of data science work do you do?  \\n\\nI'm always eager to learn more about different fields and how people use technology to solve problems. üòÑ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 118, 'total_tokens': 179, 'completion_time': 0.110909091, 'prompt_time': 0.008512123, 'queue_time': 0.0066734870000000005, 'total_time': 0.119421214}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-70aaac92-f402-42e0-a03f-1c8a66186558-0', usage_metadata={'input_tokens': 118, 'output_tokens': 61, 'total_tokens': 179}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Raja Anthonysamy. üòä  I remember!  \\n\\n\\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 192, 'total_tokens': 221, 'completion_time': 0.052727273, 'prompt_time': 0.007144538, 'queue_time': 0.007442242000000001, 'total_time': 0.059871811}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-63df76e2-5bb1-4bb5-89fc-0a4eef06ae64-0', usage_metadata={'input_tokens': 192, 'output_tokens': 29, 'total_tokens': 221})]),\n",
       " 'chat_2': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 15, 'total_tokens': 53, 'completion_time': 0.069090909, 'prompt_time': 9.9079e-05, 'queue_time': 0.015150921, 'total_time': 0.069189988}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c77e912b-d346-46f8-b218-d63b931bd163-0', usage_metadata={'input_tokens': 15, 'output_tokens': 38, 'total_tokens': 53}), HumanMessage(content='Do you know Raja Anthonysamy', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I don't have access to real-time information or personal details about individuals like Raja Anthonysamy. To find information about someone, you could try searching online using a search engine. \\n\\nIs there something specific you'd like to know about Raja Anthonysamy? Perhaps I could help you find relevant information online.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 69, 'total_tokens': 140, 'completion_time': 0.129090909, 'prompt_time': 0.002035414, 'queue_time': 0.012141406, 'total_time': 0.131126323}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bf1cfb03-f51f-481c-92d6-b31767d5c590-0', usage_metadata={'input_tokens': 69, 'output_tokens': 71, 'total_tokens': 140})])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'bound': RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       " | RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]),\n",
       " 'kwargs': {},\n",
       " 'config': {},\n",
       " 'config_factories': [],\n",
       " 'custom_input_type': None,\n",
       " 'custom_output_type': None,\n",
       " 'get_session_history': <function __main__.get_session_history(session_id: str) -> langchain_core.chat_history.BaseChatMessageHistory>,\n",
       " 'input_messages_key': None,\n",
       " 'output_messages_key': None,\n",
       " 'history_messages_key': None,\n",
       " 'history_factory_config': [ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)],\n",
       " '_history_chain': RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_msg_history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_session_history(session_id: str) -> langchain_core.chat_history.BaseChatMessageHistory>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_msg_history.get_session_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"You are my helpful assistant. Answer all the  question to thr nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Raja, it's nice to meet you!\\n\\nI'm happy to help with any questions you have.  Just ask away! üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 31, 'total_tokens': 65, 'completion_time': 0.061818182, 'prompt_time': 0.000302869, 'queue_time': 0.013866799999999999, 'total_time': 0.062121051}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-04fc5b61-7f5d-4bf3-b6be-c3ae7d17aab8-0', usage_metadata={'input_tokens': 31, 'output_tokens': 34, 'total_tokens': 65})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Raja\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Raja, it's nice to meet you!\\n\\nI'm glad you're here.  Ask me anything ‚Äì I'll do my best to help. üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 31, 'total_tokens': 71, 'completion_time': 0.072727273, 'prompt_time': 0.000360398, 'queue_time': 0.013736491, 'total_time': 0.073087671}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ad195fe-c241-494e-a7b2-8addf444b4c5-0', usage_metadata={'input_tokens': 31, 'output_tokens': 40, 'total_tokens': 71})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Raja\")]},config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç Raja! \\n\\n‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æâ‡Æ§‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç. ‡Æé‡Æ©‡Øç‡Æ©‡Ææ‡Æ≤‡Øç ‡Æá‡ÆØ‡Æ©‡Øç‡Æ±‡Æµ‡Æ∞‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡ÆÖ‡Æ©‡Øà‡Æ§‡Øç‡Æ§‡ØÅ ‡Æµ‡Æø‡Æ©‡Æµ‡Æ≤‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Æ§‡Æø‡Æ≤‡Øç ‡ÆÖ‡Æ≥‡Æø‡Æ™‡Øç‡Æ™‡Øá‡Æ©‡Øç. üòä\\n\\n‡Æé‡Æ©‡Øç‡Æ© ‡Æµ‡Æø‡Æ©‡Ææ?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 31, 'total_tokens': 88, 'completion_time': 0.103636364, 'prompt_time': 0.000376329, 'queue_time': 0.014143299, 'total_time': 0.104012693}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b23a678e-4003-4136-bf72-ade9ff225371-0', usage_metadata={'input_tokens': 31, 'output_tokens': 57, 'total_tokens': 88})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\n",
    "      \"you are my helpful assistant. Answer all question to the best of your ability in {language}\"),\n",
    "     MessagesPlaceholder(variable_name=\"messages\")]\n",
    ")\n",
    "chain=prompt|model\n",
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Raja\")],\"language\":\"Tamil\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now wrap this more complicated chain in a message history  class. this time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "config={\"configurable\":{\"session_id\":\"chat_5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi My name is Raja\")],\"language\":\"Tamil\"},config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æ∞‡Ææ‡Æú‡Ææ!  ‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æ©‡Øç‡Æ©‡Øà ‡Æö‡Øá‡Æµ‡Øà ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡Æï‡Øç‡Æï‡ØÇ‡Æü‡Æø‡ÆØ ‡Æé‡Æ©‡Øç ‡ÆÜ‡Æ§‡Æ∞‡Æµ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. üòä \\n\\n‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æé‡Æ©‡Øç‡Æ©‡ØÜ‡Æ©‡Øç‡Æ© ‡Æâ‡Æ§‡Æµ‡Æø ‡Æ§‡Øá‡Æµ‡Øà? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 148, 'total_tokens': 202, 'completion_time': 0.098181818, 'prompt_time': 0.004164686, 'queue_time': 0.010571712, 'total_time': 0.102346504}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-61799d04-8ce6-48ae-81ae-24e6231de9f4-0', usage_metadata={'input_tokens': 148, 'output_tokens': 54, 'total_tokens': 202})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my name\")],\"language\":\"Tamil\"},config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç ‡Æ∞‡Ææ‡Æú‡Ææ. \\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 214, 'total_tokens': 228, 'completion_time': 0.025454545, 'prompt_time': 0.006666447, 'queue_time': 0.006902343000000001, 'total_time': 0.032120992}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3385e177-d14b-4a6f-9902-7e252e07ec83-0', usage_metadata={'input_tokens': 214, 'output_tokens': 14, 'total_tokens': 228})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Conversation History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one important concept to understand when building chatbot is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add  a step that limits the size of the messages you are passing in.\n",
    "\n",
    "## trimmer\n",
    "\n",
    "trimmer_message helper to reduce how many messages we are sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and weather to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer=trim_messages(max_tokens=15,\n",
    "                      strategy=\"last\", \n",
    "                      token_counter=model,\n",
    "                      include_system=True,\n",
    "                      allow_partial=False,\n",
    "                      start_on=\"human\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"You are my assistant\"),\n",
    "    HumanMessage(content=\"Hi IM bob\"),\n",
    "    SystemMessage(content=\"Hi\"),\n",
    "    HumanMessage(content=\"I like vennila ice cream\"),\n",
    "    SystemMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what 2+2\"),\n",
    "    SystemMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    SystemMessage(content=\"No problem\"),\n",
    "    HumanMessage(content=\"Having fun\"),\n",
    "    SystemMessage(content=\"Yes\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are my assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what 2+2', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='No problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='Yes', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I don't store past conversations. Every interaction we have is fresh and new. \\n\\nThink of it like talking to a person ‚Äì they don't remember what you said five minutes ago unless you bring it up again.  \\n\\nIs there anything else I can help you with? üòä \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 119, 'total_tokens': 188, 'completion_time': 0.125454545, 'prompt_time': 0.003446508, 'queue_time': 0.011680639999999999, 'total_time': 0.128901053}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-de3d9a48-bd1c-4983-b334-4e9bfe142c9e-0', usage_metadata={'input_tokens': 119, 'output_tokens': 69, 'total_tokens': 188})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(message=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What are the messages u store in i passed trimmer\")],\n",
    "    \"language\":\"English\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat_6\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Bob!  üòÑ  \\n\\nWe're having a good time, aren't we?  What else can I help you with?  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 586, 'total_tokens': 621, 'completion_time': 0.063636364, 'prompt_time': 0.018540568, 'queue_time': 0.003976147999999999, 'total_time': 0.082176932}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7eb8292-ddc5-4a3e-ba1a-2b2c5f18c5b1-0', usage_metadata={'input_tokens': 586, 'output_tokens': 35, 'total_tokens': 621})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"What is my name\")],\"language\":\"English\"},config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
